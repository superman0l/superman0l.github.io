

### 光照

大多数情况下， 1个项目只使用1种渲染路径，因此我们可以为项目设置渲染时的渲染路径。

可以使用多个渲染路径，例如摄像机A渲染的物体使用前向渲染路径，而 摄像机B渲染的物体使用延迟渲染路径

可以在每个摄像机的渲染路径设胃中设詈该 摄像机使用的渲染路径，以覆盖 Project Settings 中的设置

完成设置后 ，我们就可以在每个 Pass 中使用标签来指定该 Pass 使用的渲染路径。 这是通过设置 Pass 的LightMode 标签实现

| 渲染路径     |                                                      |
| ------------ | ---------------------------------------------------- |
| Always       | 总会被渲染 但不计算任何光照                          |
| ForwardBase  | 前向渲染。环境光、平行光、逐顶点/SH光源和Lightmaps   |
| ForwardAdd   | 前向渲染。计算额外的逐像素光源，每个Pass对应一个光源 |
| Deferred     | 延迟渲染。G-buffer                                   |
| ShadowCaster | 深度信息渲染到shadowmap或深度纹理中                  |
|              |                                                      |
|              |                                                      |
|              |                                                      |

##### 前向渲染路径

```
Pass { 
    for (each primitive in this model) { 
        for (each fragment covered by this primi ive) { 
            if (failed in depth test) { 
                ／／如果没有通过深度测试，说明该片元是不可见的
                discard; 
            } else { 
                ／／如果该片元可见
                ／／就进行光照计算
                float4 color= Shading(materia1In£o, pos, normal, lightDir, viewDir); 
                ／／更新帧缓冲
                writeFrameBuffer(fragment, color); 
			}
		}
	}
}
```

对于每个逐像素光源，我们都需要进行上面一次完整的渲染流程。如果 个物体在多个逐像素光源的影响区域内，那么该物体就需要执行多个 Pass, 每个 Pass 计算一个逐像素光源的光照结 果，然后在帧缓冲中把这些光照结果混合起来得到最终的颜色值。假设，场景中有N个物体，每 个物体受M个光源的影响，那么要渲染整个场景一共需要 N*M Pass

##### Unity中前向渲染

前向渲染路径有3种处理光照（即照亮物体）的方式： 逐顶点处理、逐像素处理，球谐函数 (Spherical Harmonics, SH) 处理。

而决定一个光源使用哪种处理模式取决于它的类型和渲染模式。光源类型指的是该光源是平行光还是其他类型的光源，而光源的渲染模式指的 是该光源是否是重要的 (Important) 。如果是重要的则使用逐像素光照

Unity会根据 场景中各个光源的设置以及这些光源对物体的影响程度（例 如， 距离该物体的远近、 光源强度等）对这些光源进行一个 重要度排序。

Unity使用的判断规则如下。 

- 场景中最亮的平行光总是按逐像素处理的。 
- 渲染模式被设置成NotImportant的光源，会按逐顶点或者SH处理。 
- 渲染模式被设置成Important的光源， 会按逐像素处理。 
- 如果根据以上规则得到的逐像素光源数量小于Quality Setting中的逐像素光源数量(Pixel Light Count), 会有更多的光源以逐像素的方式进行渲染。

在BaseShadow中实现的光照：光照纹理、环境光、自发光、阴影

，对于一个物体来说， 环境光和自发光我们只希望计算一 次即可， 而如果我们在AdditionalPass中计算这两种光照， 就会造 成叠加多次环境光和自发光

在Additional Pass的渲染设置中， 我们还开启和设置了混合模式。 这是因为， 我们希望每 个AdditionalPass可以与上一次的光照结果在帧缓存中进行叠加，从而得到最终的有多个 光照的渲染效果。如果我们没有开启和设置混合模式， 那么Additional Pass的渲染结果会 覆盖掉之前的渲染结果，看起来就好像该物体只受该光源的影响。通常情况下， 我们选择 的混合模式是Blend One One

千前向渲染来说， 一个Unity Shader通常会定义一个Base Pass (Base Pass也可以定义 多次， 例如需要双面渲染等情况）以及一个Additional Pass。 一个Base Pass仅会执行一 次（定义了多个Base Pass的情况除外）， 而一个AdditionalPass会根据影响该物体的其他 逐像素光源的数目被多次调用， 即每个逐像素光源会执行一次AdditionalPass

在Shader中可访问的光照变量：

|                                                             | 类型     |                                                           |
| ----------------------------------------------------------- | -------- | --------------------------------------------------------- |
| _LightColor0                                                | float4   | 逐像素光源颜色                                            |
| _WorldSpaceLightPos0                                        | float4   | 逐像素光源位置（平行光则w=0）                             |
| _LightMatrix0                                               | float4x4 | 世界空间到光源空间的变换矩阵 用于采样cookie和光强衰减纹理 |
| unity_ 4LightPosX0, unity_ 4LightPosY0,  unity_ 4LightPosZ0 | float4   |                                                           |
| unity_ 4LigbtAtten0                                         | float4   |                                                           |
| unity_ LightColor                                           | hlaf4[4] |                                                           |

##### 前向渲染可使用的内置光照函数

| 函数名                                        | 描述                                                         |
| --------------------------------------------- | ------------------------------------------------------------ |
| `float3 WorldSpaceLightDir(float4 v)`         | 仅可用于前向渲染中 。输入一个模型空间中的顶点位置，返回世界空间中从该点到光 源的光照方向。内部实现使用了 UnityWorldSpaceLigblDir 。没有被归一化 |
| `float3  UnityWorldSpaceLightDir  (float4 v)` | 仅可用于前向渲染中 。输入一个世界空间中的顶点位置 ，返同世界空间中从该点到光源的光照方向。没有被归 |
| `float3 ObjSpaceLightDir(float4 v)`           | 仅可用前向渲染中 。输入一个模型空间中的顶点位置返回模型空间中从该点 到光源的光照方向。没有被归 |
| `float3 Shade4PointLigbts (…)`                | 仅可用干前向渲染中 。计算四个点光源的光照 ，它的参数是已经打包进矢量的光照数据，通常就是表 9.2 中的unity_xxx 变量 |

##### 顶点照明渲染路径

没什么用 不写了

##### 延迟渲染路径

当场景中包含大量实时光源时 ，前向渲染的性能会急速下降。例如，如 果我们在场景的某一块区域放置了多个光源 这些光源影响的区域互相重叠，那么为了得到最终 的光照效果，我们就需要为该区域内的每个物体执行多个 Pass 来计算不同光源对该物体的光照结 果，然后在颜色缓存中把这些结果混合起来得到最终的光照。然而，每执行一个 Pass 们都需要 重新渲染一遍物体，但很多计算实际上是重复

除了前向渲染中使用的颜色缓冲和深度缓冲外，延迟渲染还会利用额外的缓冲区，这些 缓冲区也被统称为G缓冲 （ G-buffer ),。 缓冲区存储了我们所关心的表面（通常指的是离摄像机最近的表面）的其他信息，例如该表面的法线、位置、用于光照计算的材质属性

###### 原理

主要包含了两个 Pass 。在第一个 Pass 中，我们不进行任何光照计算，而是仅仅计算 哪些片元是可见的，这主要是通过深度缓冲技术来实现，当发现一个片元是可见的，我们就把它 相关信息（位置、normal、depth、材质）存储到G缓冲区中。然后，在第二个 Pass 中，我们利用 缓冲区的各个片元信息， 例如表面法线 、视角方向、漫反射系数 ，将所有光源对每个像素进行真正的光照计算

延迟渲染（Deferred Rendering）在处理半透明物体和抗锯齿时确实存在一些挑战：

1. **半透明物体**：延迟渲染的主要思想是将几何体渲染和光照计算分离。在几何体阶段，所有的物体信息（如位置、法线、颜色等）都被存储在G缓冲（G-Buffer）中。然后在光照阶段，使用G缓冲中的信息对每个光源进行光照计算。这种方法的问题在于，它假设每个像素只有一个物体，因此无法处理半透明物体，因为半透明物体需要考虑多个物体的贡献。为了解决这个问题，通常的做法是使用混合的延迟渲染和前向渲染，即先使用延迟渲染处理不透明物体，然后使用前向渲染处理半透明物体。
2. **抗锯齿**：延迟渲染的另一个挑战是抗锯齿。在前向渲染中，可以使用多重采样抗锯齿（MSAA）来减少锯齿。然而，在延迟渲染中，由于G缓冲的存在，MSAA会增加显著的存储和带宽需求，因此通常不被使用。为了解决这个问题，通常会使用一些后处理技术，如FXAA（Fast Approximate Anti-Aliasing）或者SMAA（Subpixel Morphological Anti-Aliasing），来进行抗锯齿。

FXAA：FXAA的原理是通过提取像素界面周围的颜色信息，通过混合颜色信息来消除高对比界面所产生的锯齿。FXAA的实现过程可以分为以下几个步骤：
对比度计算：首先，计算当前处理的像素点和周围像素点的亮度对比值。当对比度值较大时，认为需要进行抗锯齿处理。
基于亮度的混合系数计算：接下来就是确定当前像素点进行混合时的系数，这里为了使结果更加精确，还需要对对角线上的四个点进行采样并计算亮度值。
计算混合方向：接下来就是确定进行混合计算的方向，锯齿边界通常不会是刚好水平或者垂直的，但是这里我们要寻找一个最接近的方向。
混合：然后就是直接根据得到的混合方向和混合权重进行混合即可。
SMAA：SMAA的原理和FXAA类似，但是整体处理更加精细。SMAA是MLAA (Morphological Antialiasing) 的一个加强版。SMAA的实现过程可以分为以下几个步骤：
边缘检测：就是简单地检测目标像素和周围点像素之间是否构成边界。
混合系数计算：包括沿着当前要计算的抗锯齿边界搜索，取得到锯齿边界结束位置的距离，获取边界拐弯处/交叉边界处信息，根据两边的距离，及边界的朝向，得到重矢量化线，并计算当前像素的覆盖率/混合系数。

##### Unity光源类型

光源属性：位置、方向、颜色、强度、衰减

计算BasePass：

如果场景中包含了多个平行光， Unity 会选择最亮的平行光传递给 Base Pass 进行逐 像素处理， 其他平行光会按照逐顶点或在 Additional Pass 中按逐像素的方式处理。如果场景中没 有任何平行光， 那么 Base Pass 会当成全黑的光源处理

```
Pass {
			// Pass for ambient light & first pixel light (directional light)
			Tags { "LightMode"="ForwardBase" }
		
			CGPROGRAM
			
			// Apparently need to add this declaration 
			#pragma multi_compile_fwdbase	// 保证光照变量被正确赋值
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			
			fixed4 _Diffuse;
			fixed4 _Specular;
			float _Gloss;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldNormal : TEXCOORD0;
				float3 worldPos : TEXCOORD1;
			};
			
			v2f vert(a2v v) {
				v2f o;
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
				
				o.worldNormal = UnityObjectToWorldNormal(v.normal);
				
				o.worldPos = mul(_Object2World, v.vertex).xyz;
				
				return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
				
				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;	// 环境光，仅在base计算一次
				
				// 处理平行光
			 	fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(worldNormal, worldLightDir));

			 	fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - i.worldPos.xyz);
			 	fixed3 halfDir = normalize(worldLightDir + viewDir);
			 	fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

				fixed atten = 1.0;
				
				return fixed4(ambient + (diffuse + specular) * atten, 1.0);
			}
			
			ENDCG
}
```

其他逐像素光源定义Additional Pass

```
Pass {
			// Pass for other pixel lights
			Tags { "LightMode"="ForwardAdd" }
			
			Blend One One // 光源颜色叠加，否则多光源结果将被覆盖
		
			CGPROGRAM
			
			// Apparently need to add this declaration
			#pragma multi_compile_fwdadd
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			#include "AutoLight.cginc"
			
			fixed4 _Diffuse;
			fixed4 _Specular;
			float _Gloss;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldNormal : TEXCOORD0;
				float3 worldPos : TEXCOORD1;
			};
			
			v2f vert(a2v v) {
				v2f o;
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
				
				o.worldNormal = UnityObjectToWorldNormal(v.normal);
				
				o.worldPos = mul(_Object2World, v.vertex).xyz;
				
				return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				// 根据不同类型的光源 判断光线方向
				#ifdef USING_DIRECTIONAL_LIGHT
					fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
				#else
					fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz - i.worldPos.xyz);
				#endif
				
				fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(worldNormal, worldLightDir));
				
				fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - i.worldPos.xyz);
				fixed3 halfDir = normalize(worldLightDir + viewDir);
				fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);
				// 根据不同类型的光源处理衰减
				#ifdef USING_DIRECTIONAL_LIGHT
					fixed atten = 1.0;
				#else
					#if defined (POINT)
				        float3 lightCoord = mul(_LightMatrix0, float4(i.worldPos, 1)).xyz;
				        fixed atten = tex2D(_LightTexture0, dot(lightCoord, lightCoord).rr).UNITY_ATTEN_CHANNEL;
				    #elif defined (SPOT)
				        float4 lightCoord = mul(_LightMatrix0, float4(i.worldPos, 1));
				        fixed atten = (lightCoord.z > 0) * tex2D(_LightTexture0, lightCoord.xy / lightCoord.w + 0.5).w * tex2D(_LightTextureB0, dot(lightCoord, lightCoord).rr).UNITY_ATTEN_CHANNEL;
				    #else
				        fixed atten = 1.0;
				    #endif
				#endif

				return fixed4((diffuse + specular) * atten, 1.0);
			}
			
			ENDCG
		}
```

##### Unity光照衰减

###### 使用光照衰减的纹理

计算衰减不依赖千数学公式的复杂性，我们只要使用1个参数值去纹理中采样即可

- 需要预处理得到采样纹理，而且纹理的大小也会影响衰减的精度。 
- 不直观，同时也不方便，因此 旦把数据存储到查找表中，我们就无法使用其他数学公式来计算衰减。

Unity 在内部使用 张名为`_LightTexture0` 的纹理来计算光源衰减。我们通常只关心`_LightTexture0` 对角线上的纹理颜色值，这些值表明了在光源空间中不同位置的点的衰减 值。例如， (0, 0) 点表明了与光源重合的点的衰减值，而(1, 1) 点表明了在光源空间中所关心的 距离最远的点的衰减。

我们只需要把 LightMatrix0 和世界空间中的顶点坐标相乘即可得到光源空间中的相应位置，然后，我们可以使用这个坐标的模的平方对衰减纹理进行采样，得到衰减值

###### 数学公式计算衰减

这本书里只能通过距离来计算，可能URP里不一样

##### Unity阴影

Unity 选择使用一个额外的 Pass 来专门更新光源的阴影映射纹理，这个 Pass 就是 LigbtMode 标签被设置为`ShadowCaster Pass` 这个 Pass 的渲染目标不是帧缓存，而是阴影映射纹理（或深度纹理） Unity 首先把摄像机放置到光源的位置上，然后调用该 Pass, 通过对顶点变换后得到光源空间下的位胃，并据此来输出深度信息到阴影映射纹理中。因此，当开启了光源的阴影效果后，底层渲染引擎首先会在当前渲染物体的 Unity Shader 中找到 LigbtMode ShadowCaster Pass, 如果没有，它就会在 Fallback 指定的 Unity Shader 中继续寻找，如果仍然没有找到该物体就无法向其他物体投射阴影（但它仍然可以接收来自其他物体的阴影） 当找到了 LigbtMode SbadowCaster Pass 后， Unity 会使用该 Pass 来更新光源的阴影映射纹理

在传统的阴影映射纹理的实现中，我们会在正常渲染的 Pass 中把顶点位置变换到光源空间下，以得到它在光源空间中的三维位置信息 然后，我们使用 xy 分量对阴影映射纹理进行采样， 得到阴影映射纹理中该位置的深度信息。

Unity 使用了不同于传统Shadowmap的阴影采样技术，即**屏幕空间的阴影映射技术 (Screenspace Shadow Map)**。Unity 首先会通过调用 `LightMode ShadowCaster Pass` 来得到可投射阴影的光源的阴影映射纹理以及摄像机的深度纹理。然后，根据光源的阴影映射 纹理和摄像机的深度纹理来得到屏骆空间的阴影图。如果摄像机的深度图中记录的表面深度大于转 换到阴影映射纹理中的深度值，就说明该表面虽然是可见的但处于该光源的阴影

（在tiny_renderer中用的就是屏幕空间阴影）

阴影坐标的传递：在顶点着色器中，使用了TRANSFER_SHADOW(o);。这个宏的作用是将阴影坐标从顶点着色器传递到片段着色器。在Unity中，阴影坐标是用于采样阴影纹理的屏幕空间纹理坐标。
阴影衰减的计算：在片段着色器中，使用了fixed shadow = SHADOW_ATTENUATION(i);。这个宏的作用是计算阴影衰减。阴影衰减是一个介于0和1之间的值，表示阴影的强度。在Unity中，阴影衰减是通过比较深度纹理和阴影映射纹理得到的1。



```
SubShader {
		Tags { "RenderType"="Opaque" }
		
		Pass {
			// Pass for ambient light & first pixel light (directional light)
			Tags { "LightMode"="ForwardBase" }
		
			CGPROGRAM
			
			// Apparently need to add this declaration 
			#pragma multi_compile_fwdbase	
			
			#pragma vertex vert
			#pragma fragment frag
			
			// Need these files to get built-in macros
			#include "Lighting.cginc"
			#include "AutoLight.cginc"
			
			fixed4 _Diffuse;
			fixed4 _Specular;
			float _Gloss;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldNormal : TEXCOORD0;
				float3 worldPos : TEXCOORD1;
				// 用于记录shadowmap的宏
				SHADOW_COORDS(2)
			};
			
			v2f vert(a2v v) {
			 	v2f o;
			 	o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
			 	
			 	o.worldNormal = UnityObjectToWorldNormal(v.normal);

			 	o.worldPos = mul(_Object2World, v.vertex).xyz;
			 	
			 	// Pass shadow coordinates to pixel shader
			 	TRANSFER_SHADOW(o);
			 	
			 	return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
				
				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

			 	fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(worldNormal, worldLightDir));

			 	fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - i.worldPos.xyz);
			 	fixed3 halfDir = normalize(worldLightDir + viewDir);
			 	fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

				fixed atten = 1.0;
				
				fixed shadow = SHADOW_ATTENUATION(i);
				
				return fixed4(ambient + (diffuse + specular) * atten * shadow, 1.0);
			}
			
			ENDCG
		}
	
		Pass {
			// Pass for other pixel lights
			Tags { "LightMode"="ForwardAdd" }
			
			Blend One One
		
			CGPROGRAM
			
			// Apparently need to add this declaration
			#pragma multi_compile_fwdadd
			// Use the line below to add shadows for point and spot lights
//			#pragma multi_compile_fwdadd_fullshadows
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			#include "AutoLight.cginc"
			
			fixed4 _Diffuse;
			fixed4 _Specular;
			float _Gloss;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 position : SV_POSITION;
				float3 worldNormal : TEXCOORD0;
				float3 worldPos : TEXCOORD1;
			};
			
			v2f vert(a2v v) {
			 	v2f o;
			 	o.position = mul(UNITY_MATRIX_MVP, v.vertex);
			 	
			 	o.worldNormal = UnityObjectToWorldNormal(v.normal);
			 	
			 	o.worldPos = mul(_Object2World, v.vertex).xyz;
			 	
			 	return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				#ifdef USING_DIRECTIONAL_LIGHT
					fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
				#else
					fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz - i.worldPos.xyz);
				#endif

			 	fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(worldNormal, worldLightDir));

			 	fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - i.worldPos.xyz);
			 	fixed3 halfDir = normalize(worldLightDir + viewDir);
			 	fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

				#ifdef USING_DIRECTIONAL_LIGHT
					fixed atten = 1.0;
				#else
					float3 lightCoord = mul(_LightMatrix0, float4(i.worldPos, 1)).xyz;
					fixed atten = tex2D(_LightTexture0, dot(lightCoord, lightCoord).rr).UNITY_ATTEN_CHANNEL;
				#endif
			 	
				return fixed4((diffuse + specular) * atten, 1.0);
			}
			
			ENDCG
		}
}
```

###### 统一管理光照衰减和阴影

其实就是在两个pass都用了unity的内置函数计算光照强度和阴影

```
SubShader {
		Tags { "RenderType"="Opaque" }
		
		Pass {
			// Pass for ambient light & first pixel light (directional light)
			Tags { "LightMode"="ForwardBase" }
		
			CGPROGRAM
			
			// Apparently need to add this declaration
			#pragma multi_compile_fwdbase	
			
			#pragma vertex vert
			#pragma fragment frag
			
			// Need these files to get built-in macros
			#include "Lighting.cginc"
			#include "AutoLight.cginc"
			
			fixed4 _Diffuse;
			fixed4 _Specular;
			float _Gloss;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldNormal : TEXCOORD0;
				float3 worldPos : TEXCOORD1;
				SHADOW_COORDS(2)
			};
			
			v2f vert(a2v v) {
			 	v2f o;
			 	o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
			 	
			 	o.worldNormal = UnityObjectToWorldNormal(v.normal);
			 	
			 	o.worldPos = mul(_Object2World, v.vertex).xyz;
			 	
			 	// Pass shadow coordinates to pixel shader
			 	// 用于计算阴影坐标并将其传递给片元着色器
			 	TRANSFER_SHADOW(o);
			 	
			 	return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
				// UnityWorldSpaceLightDir：返回从世界空间中的一个点到主光源的方向向量
				
				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;
				
			 	fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(worldNormal, worldLightDir));

			 	fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));
			 	fixed3 halfDir = normalize(worldLightDir + viewDir);
			 	fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

				// UNITY_LIGHT_ATTENUATION not only compute attenuation, but also shadow infos
				// UNITY_LIGHT_ATTENUATION：用于计算光照衰减和阴影信息。
				UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);
				
				return fixed4(ambient + (diffuse + specular) * atten, 1.0);
			}
			
			ENDCG
		}
	
		Pass {
			// Pass for other pixel lights
			Tags { "LightMode"="ForwardAdd" }
			
			Blend One One
		
			CGPROGRAM
			
			// Apparently need to add this declaration
			#pragma multi_compile_fwdadd
			// Use the line below to add shadows for point and spot lights
//			#pragma multi_compile_fwdadd_fullshadows
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			#include "AutoLight.cginc"
			
			fixed4 _Diffuse;
			fixed4 _Specular;
			float _Gloss;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldNormal : TEXCOORD0;
				float3 worldPos : TEXCOORD1;
				SHADOW_COORDS(2)
			};
			
			v2f vert(a2v v) {
			 	v2f o;
			 	o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
			 	
			 	o.worldNormal = UnityObjectToWorldNormal(v.normal);
			 	
			 	o.worldPos = mul(_Object2World, v.vertex).xyz;
			 	
			 	// Pass shadow coordinates to pixel shader
			 	TRANSFER_SHADOW(o);
			 	
			 	return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
				
			 	fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * max(0, dot(worldNormal, worldLightDir));

			 	fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));
			 	fixed3 halfDir = normalize(worldLightDir + viewDir);
			 	fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

				// UNITY_LIGHT_ATTENUATION not only compute attenuation, but also shadow infos
				UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);
			 	
				return fixed4((diffuse + specular) * atten, 1.0);
			}
			
			ENDCG
		}
}
```

##### 透明物体的阴影

```
SubShader {
		Tags {"Queue"="AlphaTest" "IgnoreProjector"="True" "RenderType"="TransparentCutout"}
		
		Pass {
			Tags { "LightMode"="ForwardBase" }
			
			Cull Off
			
			CGPROGRAM
			
			#pragma multi_compile_fwdbase
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			#include "AutoLight.cginc"
			
			fixed4 _Color;
			sampler2D _MainTex;
			float4 _MainTex_ST;
			fixed _Cutoff;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
				float4 texcoord : TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldNormal : TEXCOORD0;
				float3 worldPos : TEXCOORD1;
				float2 uv : TEXCOORD2;
				SHADOW_COORDS(3)
			};
			
			v2f vert(a2v v) {
			 	v2f o;
			 	o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
			 	
			 	o.worldNormal = UnityObjectToWorldNormal(v.normal);
			 	
			 	o.worldPos = mul(_Object2World, v.vertex).xyz;

			 	o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);
			 	
			 	// Pass shadow coordinates to pixel shader
			 	TRANSFER_SHADOW(o);
			 	
			 	return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
				
				fixed4 texColor = tex2D(_MainTex, i.uv);

				clip (texColor.a - _Cutoff);
				
				fixed3 albedo = texColor.rgb * _Color.rgb;
				
				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
				
				fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(worldNormal, worldLightDir));
							 	
			 	// UNITY_LIGHT_ATTENUATION not only compute attenuation, but also shadow infos
				UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);
			 	
				return fixed4(ambient + diffuse * atten, 1.0);
			}
			
			ENDCG
		}
	} 
	FallBack "Transparent/Cutout/VertexLit"
```

如果使用`Fallback "VertexLit"` ，透明镂空区域会出现不正常的阴影，看起来就像这个正方体是一个普通的 正方体一样。我们希望有些光应该是可以通过这些镂空区域透过来 的，这些区域不应该有阴影。出现这样的情况是因为，我们使用的 VertexLit 中提供的 ShadowCaster 来投射阴影，而这个 Pass 中并没有进行任何透明度测试的计算，因此，它会把整 个物体的深度信息渲染到深度图和阴影映射纹理中

但需要注意的是，由 Transparent/Cutout/VertexLit 中计算透明度测试时，使用了名为`_Cutoff` 的属性来进行透明度测试，因此，这要求我们的 Shader 中也必须提供名为`_Cutoff` 属性

事实上，Unity所有内置的透明度混合的 Unity Shader, Transparent/Vertex.Lit 等，都没有包含阴影投射的 Pass 这意味着，这些半透明物体不会参与深度图和阴影映射纹理的计算，也就是说，它们不会向其他物体 投射阴影，同样它们也不会接收来自其他物体的阴影

由于透明度混合需要关闭深度写入，同时要产生正确的阴影需要在每个光源空间下仍然严格按照从后往前的顺序进行渲染，就需要额外对物体的深度进行排列。这会让阴影处理变得非常复杂，而且也会影响性能。

### 高级纹理

##### 立方体纹理Cubemap

立方体纹理时环境映射Environment Mapping的一种实现方式，环境映射使得看起来像镀层金属反射

对立方体纹理采样需要提供三维威力坐标，表示在世界空间下的3D方向，该方向从立方体中心出发，当它向外部延伸时就会和立方体的纹理发生相交，采样结果即为该交点计算得出。

立方体纹理的好处在于实现简单且得到效果好，缺点为场景变化时需要重新生成

###### 天空盒子Skybox

创建Skybox材质：

- 新建材质 选择Skybox/6 Sided 该材质要6张纹理
- 把6张纹理的Wrap Mode 设置为Clamp 防止接缝处不匹配
- skybox材质还有Tint Color属性用于控制整体颜色、Exposure用于调整亮度、Rotation调整沿y轴方向的旋转角度
- 在Lighting中把SkyboxMat赋给Skybox
- 把摄像机的Camera组件的Clear Flags设置为Skybox

###### 用于环境映射的立方体纹理

三种创建立方体纹理的方法：直接由特殊布局的纹理创建、手动创建Cubemap再赋6张图、脚本生成

第一种方法需要提供一张有特殊布局的纹理，把纹理的Texture Type 设置为Cubemap

第二种方法创建Cubemap再把六张纹理拖进去

第三种方法使用Camera.RenderToCubemap函数，该函数由Unity'提供，可以把任意位置观察到的场景图象存储到六张图像中

###### 反射

在片元着色器中使用世界空间的反射向量来从立方体纹理中采样出反射颜色。最后，它将漫反射颜色和反射颜色混合在一起，得到最终的颜色

世界空间的反射向量是在顶点着色器`vert`函数中计算出来的。具体的计算过程是使用内置的`reflect`函数，该函数接受两个参数：一个是入射光线的方向，另一个是表面的法线。在这里，入射光线的方向是观察方向的反方向（由`-o.worldViewDir`表示），表面的法线是`o.worldNormal`。计算反射向量的公式如下：
$$
反射向量=reflect(−观察方向,法线)
$$

- `_ReflectColor`：这是一个颜色值，用于调整反射颜色。在片元着色器`frag`函数中，它与立方体纹理采样出的颜色进行了乘法运算，从而改变了反射的颜色。
- `_ReflectAmount`：这是一个范围在0到1之间的值，用于调整反射颜色和漫反射颜色之间的混合比例。在`frag`函数中，它被用作`lerp`函数的第三个参数，当`_ReflectAmount`为0时，输出的颜色完全是漫反射颜色；当`_ReflectAmount`为1时，输出的颜色完全是反射颜色。当`_ReflectAmount`在0和1之间时，输出的颜色是漫反射颜色和反射颜色的混合。

```
Properties {
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_ReflectColor ("Reflection Color", Color) = (1, 1, 1, 1)
		_ReflectAmount ("Reflect Amount", Range(0, 1)) = 1
		_Cubemap ("Reflection Cubemap", Cube) = "_Skybox" {}
	}
SubShader {
    Tags { "RenderType"="Opaque" "Queue"="Geometry"}

    Pass { 
        Tags { "LightMode"="ForwardBase" }

        CGPROGRAM

            #pragma multi_compile_fwdbase

            #pragma vertex vert
            #pragma fragment frag

            #include "Lighting.cginc"
            #include "AutoLight.cginc"

            fixed4 _Color;
        fixed4 _ReflectColor;
        fixed _ReflectAmount;
        samplerCUBE _Cubemap;

        struct a2v {
            float4 vertex : POSITION;
            float3 normal : NORMAL;
        };

        struct v2f {
            float4 pos : SV_POSITION;
            float3 worldPos : TEXCOORD0;
            fixed3 worldNormal : TEXCOORD1;
            fixed3 worldViewDir : TEXCOORD2;
            fixed3 worldRefl : TEXCOORD3;
            SHADOW_COORDS(4)
        };

        v2f vert(a2v v) {
            v2f o;

            o.pos = mul(UNITY_MATRIX_MVP, v.vertex);

            o.worldNormal = UnityObjectToWorldNormal(v.normal);

            o.worldPos = mul(_Object2World, v.vertex).xyz;

            o.worldViewDir = UnityWorldSpaceViewDir(o.worldPos);

            // Compute the reflect dir in world space
            o.worldRefl = reflect(-o.worldViewDir, o.worldNormal);

            TRANSFER_SHADOW(o);

            return o;
        }

        fixed4 frag(v2f i) : SV_Target {
            fixed3 worldNormal = normalize(i.worldNormal);
            fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));		
            fixed3 worldViewDir = normalize(i.worldViewDir);		

            fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

            fixed3 diffuse = _LightColor0.rgb * _Color.rgb * max(0, dot(worldNormal, worldLightDir));

            // Use the reflect dir in world space to access the cubemap
            // 立方体纹理取样
            fixed3 reflection = texCUBE(_Cubemap, i.worldRefl).rgb * _ReflectColor.rgb;

            UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

            // Mix the diffuse color with the reflected color
            fixed3 color = ambient + lerp(diffuse, reflection, _ReflectAmount) * atten;

            return fixed4(color, 1.0);
        }

        ENDCG
    }
}
```

###### 折射

使用公式计算折射夹角
$$
n_1sin{\theta}_1 = n_2sin{\theta}_2
$$
不过shader都是直接调内置函数来算 没什么好说的 计算折射角度

```
Properties {
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_RefractColor ("Refraction Color", Color) = (1, 1, 1, 1)
		_RefractAmount ("Refraction Amount", Range(0, 1)) = 1
		_RefractRatio ("Refraction Ratio", Range(0.1, 1)) = 0.5
		_Cubemap ("Refraction Cubemap", Cube) = "_Skybox" {}
	}
SubShader {
    Tags { "RenderType"="Opaque" "Queue"="Geometry"}

    Pass { 
        Tags { "LightMode"="ForwardBase" }

        CGPROGRAM

            #pragma multi_compile_fwdbase	

            #pragma vertex vert
            #pragma fragment frag

            #include "Lighting.cginc"
            #include "AutoLight.cginc"

            fixed4 _Color;
        fixed4 _RefractColor;
        float _RefractAmount;
        fixed _RefractRatio;
        samplerCUBE _Cubemap;

        struct a2v {
            float4 vertex : POSITION;
            float3 normal : NORMAL;
        };

        struct v2f {
            float4 pos : SV_POSITION;
            float3 worldPos : TEXCOORD0;
            fixed3 worldNormal : TEXCOORD1;
            fixed3 worldViewDir : TEXCOORD2;
            fixed3 worldRefr : TEXCOORD3;
            SHADOW_COORDS(4)
        };

        v2f vert(a2v v) {
            v2f o;
            o.pos = mul(UNITY_MATRIX_MVP, v.vertex);

            o.worldNormal = UnityObjectToWorldNormal(v.normal);

            o.worldPos = mul(_Object2World, v.vertex).xyz;

            o.worldViewDir = UnityWorldSpaceViewDir(o.worldPos);

            // Compute the refract dir in world space
            o.worldRefr = refract(-normalize(o.worldViewDir), normalize(o.worldNormal), _RefractRatio);

            TRANSFER_SHADOW(o);

            return o;
        }

        fixed4 frag(v2f i) : SV_Target {
            fixed3 worldNormal = normalize(i.worldNormal);
            fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
            fixed3 worldViewDir = normalize(i.worldViewDir);

            fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

            fixed3 diffuse = _LightColor0.rgb * _Color.rgb * max(0, dot(worldNormal, worldLightDir));

            // Use the refract dir in world space to access the cubemap
            fixed3 refraction = texCUBE(_Cubemap, i.worldRefr).rgb * _RefractColor.rgb;

            UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

            // Mix the diffuse color with the refract color
            fixed3 color = ambient + lerp(diffuse, refraction, _RefractAmount) * atten;

            return fixed4(color, 1.0);
        }

        ENDCG
    }
} 
FallBack "Reflective/VertexLit"
```

###### 菲涅尔反射 Fresnel reflection

Schlick菲涅尔近似等式：
$$
F_{schlick}(v,n)=F_0+(1-F_0)(1-v\dotproduct n)^5
$$
$F_0$是反射系数，用于控制菲涅尔反射的强度，v是视角方向，n是表面法线

Empricial菲涅尔近似等式
$$
F_{Empricial}(v,n)=max(0,min(1,bias+scale*(1-v \dotproduct n)^{power}))
$$

```
Shader "Unity Shaders Book/Chapter 10/Fresnel" {
	Properties {
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_FresnelScale ("Fresnel Scale", Range(0, 1)) = 0.5
		_Cubemap ("Reflection Cubemap", Cube) = "_Skybox" {}
	}
	SubShader {
		Tags { "RenderType"="Opaque" "Queue"="Geometry"}
		
		Pass { 
			Tags { "LightMode"="ForwardBase" }
		
			CGPROGRAM
			
			#pragma multi_compile_fwdbase
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			#include "AutoLight.cginc"
			
			fixed4 _Color;
			fixed _FresnelScale;
			samplerCUBE _Cubemap;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float3 worldPos : TEXCOORD0;
  				fixed3 worldNormal : TEXCOORD1;
  				fixed3 worldViewDir : TEXCOORD2;
  				fixed3 worldRefl : TEXCOORD3;
 	 			SHADOW_COORDS(4)
			};
			// 顶点着色器获取法线和视角方向
			v2f vert(a2v v) {
				v2f o;
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
				
				o.worldNormal = UnityObjectToWorldNormal(v.normal);
				
				o.worldPos = mul(_Object2World, v.vertex).xyz;
				
				o.worldViewDir = UnityWorldSpaceViewDir(o.worldPos);
				
				o.worldRefl = reflect(-o.worldViewDir, o.worldNormal);
				
				TRANSFER_SHADOW(o);
				
				return o;
			}
			// 片元着色器计算菲涅尔系数
			fixed4 frag(v2f i) : SV_Target {
				fixed3 worldNormal = normalize(i.worldNormal);
				fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
				fixed3 worldViewDir = normalize(i.worldViewDir);
				
				fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;
				
				UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);
				
				fixed3 reflection = texCUBE(_Cubemap, i.worldRefl).rgb;
				
				fixed fresnel = _FresnelScale + (1 - _FresnelScale) * pow(1 - dot(worldViewDir, worldNormal), 5);
				
				fixed3 diffuse = _LightColor0.rgb * _Color.rgb * max(0, dot(worldNormal, worldLightDir));
				
				fixed3 color = ambient + lerp(diffuse, reflection, saturate(fresnel)) * atten;
				
				return fixed4(color, 1.0);
			}
			
			ENDCG
		}
	} 
	FallBack "Reflective/VertexLit"
}
```

##### 渲染纹理

GPU允许把整个三维场景渲染到一个中间缓冲中，即 **渲染目标纹理 Render Target Texture， RTT**， 与之相关的是 **多重渲染目标 Multiple Render Target， MRT**,GPU允许把场景同时渲染到多个渲染目标纹理中。

Unity定义 **渲染纹理Render Texture** ，Unity中使用渲染纹理通常有两种方式：Project目录创造渲染纹理并把摄像机的渲染目标设置成该渲染纹理，摄像机的渲染结果就是实时更新到渲染纹理中；另一种方式是在屏幕后处理时使用GrabPass命令或OnRenderImage函数来获取当前屏幕图像，Unity会把这个屏幕图像放到一张和屏幕分辨率等同的渲染纹理中 。

###### 镜子效果

shader的实现如下 就是最基本的Shader，然后在片元着色器中把x反转了（镜子左右翻转）

```
SubShader {
    Tags { "RenderType"="Opaque" "Queue"="Geometry"}

    Pass {
        CGPROGRAM

            #pragma vertex vert
            #pragma fragment frag

            sampler2D _MainTex;

        struct a2v {
            float4 vertex : POSITION;
            float3 texcoord : TEXCOORD0;
        };

        struct v2f {
            float4 pos : SV_POSITION;
            float2 uv : TEXCOORD0;
        };

        v2f vert(a2v v) {
            v2f o;
            o.pos = mul(UNITY_MATRIX_MVP, v.vertex);

            o.uv = v.texcoord;
            // Mirror needs to filp x
            o.uv.x = 1 - o.uv.x;

            return o;
        }

        fixed4 frag(v2f i) : SV_Target {
            return tex2D(_MainTex, i.uv);
        }

        ENDCG
    }
} 
```

注意在实现中考虑渲染纹理的分辨率大小，如果设置太高会影响性能

###### 玻璃效果

当我们在 Shader 中定义了一个 GrabPass 后， Unity 会把当前屏幕的图像绘制在 一张纹理中 ，以便我们在后续的 Pass 中访问它 。我们通常会使用 GrabPass 来实现诸如玻璃等透 明材质的模拟，与使用简单的透明混合不同，使用 GrabPass 可以让我们对该物体后面的图像进行 更复杂的处理，例如使用法线来模拟折射效果，而不再是简单的和原屏幕颜色进行混合。

当使用了GrabPass的Shader作用在一个物体上，`GrabPass`会抓取整个屏幕内容，并将其存储到一个纹理中。而我们会通过这个物体的片元得到其在屏幕中的位置，根据在屏幕中的位置对于这个物体的屏幕内容进行更改，从而实现根据GrabPass对于在半透明物体之后的内容的修改。这个纹理在Shader的下一个Pass中可以通过`_RefractionTex`来访问，用于实现效果。

GrabPass 通常用于渲染透明物体，尽管代码里并不包含混合指令，但我们往往仍然需要把 物体的渲染队列设置成透明队列（即"Queue"="Transparent") 。这样才可以保证当渲染该物体时， 所有的不透明物体都已经被绘制在屏幕上，从而获取正确的屏幕图像。

首先在 SubShader 的标签中将渲染队列设置成 Transparent, 尽管在后面的 RenderType 设置为了 Opaque 。这两者看似矛盾，但实际上服务于不同的需求。我们在之前说过，把 Queue 设置成 Transparent 可以确保该物体渲染时，其他所有不透明物体都已经被渲染到屏幕上了，否则 就可能无法正确得到“透过玻璃看到的图像”。而设置 RenderType 则是为了在使用着色器替换 (Shader Replacement) 时，该物体可以在需要时被正确渲染。

```
Shader "Unity Shaders Book/Chapter 10/Glass Refraction" {
	// Properties：这部分定义了Shader的属性
	// 主纹理(_MainTex)，法线贴图(_BumpMap)
	// 环境立方体贴图(_Cubemap)，扭曲度(_Distortion)和折射量(_RefractAmount)
	Properties {
		_MainTex ("Main Tex", 2D) = "white" {}
		_BumpMap ("Normal Map", 2D) = "bump" {}
		_Cubemap ("Environment Cubemap", Cube) = "_Skybox" {}
		_Distortion ("Distortion", Range(0, 100)) = 10
		_RefractAmount ("Refract Amount", Range(0.0, 1.0)) = 1.0
	}
	
	SubShader {
		// We must be transparent, so other objects are drawn before this one.
		Tags { "Queue"="Transparent" "RenderType"="Opaque" }
		
		// This pass grabs the screen behind the object into a texture.
		// We can access the result in the next pass as _RefractionTex
		// 这个Pass会抓取当前物体背后的屏幕内容到一个纹理中
		// 这个纹理可以在下一个Pass中作为_RefractionTex访问。这个纹理用于实现折射效果
		GrabPass { "_RefractionTex" }
		
		Pass {		
			CGPROGRAM
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "UnityCG.cginc"
			
			sampler2D _MainTex;
			float4 _MainTex_ST;
			sampler2D _BumpMap;
			float4 _BumpMap_ST;
			samplerCUBE _Cubemap;
			float _Distortion;
			fixed _RefractAmount;
			// 使用GrabPass指定的纹理名称 以及得到该纹理的纹素大小
			sampler2D _RefractionTex;
			float4 _RefractionTex_TexelSize;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
				float4 tangent : TANGENT; 
				float2 texcoord: TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float4 scrPos : TEXCOORD0;
				float4 uv : TEXCOORD1;
				float4 TtoW0 : TEXCOORD2;  
			    float4 TtoW1 : TEXCOORD3;  
			    float4 TtoW2 : TEXCOORD4; 
			};
			
			v2f vert (a2v v) {
				v2f o;
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
				
				o.scrPos = ComputeGrabScreenPos(o.pos);
				// 采样坐标
				o.uv.xy = TRANSFORM_TEX(v.texcoord, _MainTex);
				o.uv.zw = TRANSFORM_TEX(v.texcoord, _BumpMap);
				
				float3 worldPos = mul(_Object2World, v.vertex).xyz;  
				fixed3 worldNormal = UnityObjectToWorldNormal(v.normal);  
				fixed3 worldTangent = UnityObjectToWorldDir(v.tangent.xyz);  
				fixed3 worldBinormal = cross(worldNormal, worldTangent) * v.tangent.w; 
				// 从切线空间到世界空间得到变换矩阵，并把每一行分别存储在xyz分量种
				// 切线 副切线和法线
				o.TtoW0 = float4(worldTangent.x, worldBinormal.x, worldNormal.x, worldPos.x);  
				o.TtoW1 = float4(worldTangent.y, worldBinormal.y, worldNormal.y, worldPos.y);  
				o.TtoW2 = float4(worldTangent.z, worldBinormal.z, worldNormal.z, worldPos.z);  
				
				return o;
			}
			
			fixed4 frag (v2f i) : SV_Target {		
				float3 worldPos = float3(i.TtoW0.w, i.TtoW1.w, i.TtoW2.w);
				// 该片元的视角方向
				fixed3 worldViewDir = normalize(UnityWorldSpaceViewDir(worldPos));
				
				// Get the normal in tangent space
				// 对法线纹理采样得到切线空间下法线方向
				fixed3 bump = UnpackNormal(tex2D(_BumpMap, i.uv.zw));	
				
				//选择使用切线空间下法线方向来进行 是因为该空间下的法线可以反映顶点局部空间下的法线方向
				// Compute the offset in tangent space
				float2 offset = bump.xy * _Distortion * _RefractionTex_TexelSize.xy;
				i.scrPos.xy = offset * i.scrPos.z + i.scrPos.xy;
				// 对抓取的屏幕对象进行采样得到模拟的折射颜色
				fixed3 refrCol = tex2D(_RefractionTex, i.scrPos.xy/i.scrPos.w).rgb;
				
				// Convert the normal to world space 法线转为世界空间
				bump = normalize(half3(dot(i.TtoW0.xyz, bump), dot(i.TtoW1.xyz, bump), dot(i.TtoW2.xyz, bump)));
				fixed3 reflDir = reflect(-worldViewDir, bump);
				fixed4 texColor = tex2D(_MainTex, i.uv.xy);
				// 通过反射对cubemap采样
				fixed3 reflCol = texCUBE(_Cubemap, reflDir).rgb * texColor.rgb;
				
				fixed3 finalColor = reflCol * (1 - _RefractAmount) + refrCol * _RefractAmount;
				
				return fixed4(finalColor, 1);
			}
			
			ENDCG
		}
	}
	
	FallBack "Diffuse"
}
```

GrabPass 支持两种形式：

- 直接使用 GrabPass { } , 然后在后续的 Pass 中直接使用_Grab Texture 来访问屏幕图像。但 是，当场景中有多个物体都使用了这样的形式来抓取屏幕时，这种方法的性能消耗比较大， 因为对于每个使用它的物体， Unity 都会为它单独进行一次昂贵的屏幕抓取操作。但这种方法可以让每个物体得到不同的屏幕图像，这取决千它们的渲染队列及渲染它们时当前的屏幕缓冲中的颜色。 
- 使用 GrabPass { "TextureName" } , 正如本节中的实现，我们可以在后续的 Pass 中使用 TextureName 来访问屏幕图像。使用这种方法同样可以抓取屏幕，但 Unity 只会在每一帧时为第一个使用名为 TextureName 纹理的物体执行一次抓取屏幕的操作，而这个纹理同 样可以在其他 Pass 中被访问。这种方法更高效，因为不管场景中有多少物体使用了该命 令，每一帧中 nity 都只会执行1次抓取工作，但这也意味着所有物体都会使用同1张屏幕图像。不过，在大多数情况下这已经足够了。

###### 渲染纹理 vs GrabPass

从效率上来讲，使用渲染纹理的效率往往要好于 rabPass, 尤其在移动设备上。使用渲染 纹理我们可以自定义渲染纹理的大小，尽管这种方法需要把部分场景再次渲染一遍，但我们可以 通过调整摄像机的渲染层来减少二次渲染时的场景大小，或使用其他方法来控制摄像机是否需要 开启。

而使用 GrabPass 获取到的图像分辨率和显示屏幕是一致的，这意味着在一些高分辨率的设备上可能会造成严重的带宽影响。而且在移动设备上， GrabPass 虽然不会重新渲染场景，但它往 往要 CPU 直接读取后备缓冲 (back buffer) 中的数据，破坏了 CPU GPU 之间的并行性，这 是比较耗时的，甚至在 些移动设备上这是不支持的。

##### 程序纹理

###### Unity的简单程序纹理

计算机生成的图像，使用特定的算法创建个性化图案或自然元素。

使用程序纹理可以使用各种参数控制纹理外观

cs代码生成程序纹理：

为了在面板上修改属性时仍可以执行 set 函数，使用了一个开源插件 [SetProperty](https://github.com/LMNRY/SetProperty/blob/master/Scripts/SetPropertyExample.cs) 。这使得当我们在inspector修改了材质属性时，可以执行 UpdateMaterial 函数来使用新的属性重新生成程序纹理。

```c#
using UnityEngine;
using System.Collections;
using System.Collections.Generic;

[ExecuteInEditMode]
public class ProceduralTextureGeneration : MonoBehaviour {

	public Material material = null;

	#region Material properties
	[SerializeField, SetProperty("textureWidth")]
	private int m_textureWidth = 512;
	public int textureWidth {
		get {
			return m_textureWidth;
		}
		set {
			m_textureWidth = value;
			_UpdateMaterial();
		}
	}

	[SerializeField, SetProperty("backgroundColor")]
	private Color m_backgroundColor = Color.white;
	public Color backgroundColor {
		get {
			return m_backgroundColor;
		}
		set {
			m_backgroundColor = value;
			_UpdateMaterial();
		}
	}

	[SerializeField, SetProperty("circleColor")]
	private Color m_circleColor = Color.yellow;
	public Color circleColor {
		get {
			return m_circleColor;
		}
		set {
			m_circleColor = value;
			_UpdateMaterial();
		}
	}

	[SerializeField, SetProperty("blurFactor")]
	private float m_blurFactor = 2.0f;
	public float blurFactor {
		get {
			return m_blurFactor;
		}
		set {
			m_blurFactor = value;
			_UpdateMaterial();
		}
	}
	#endregion

	private Texture2D m_generatedTexture = null;

	// Use this for initialization
	void Start () {
		if (material == null) {
			Renderer renderer = gameObject.GetComponent<Renderer>();
			if (renderer == null) {
				Debug.LogWarning("Cannot find a renderer.");
				return;
			}

			material = renderer.sharedMaterial;
		}

		_UpdateMaterial();
	}

	private void _UpdateMaterial() {
		if (material != null) {
			m_generatedTexture = _GenerateProceduralTexture();
			material.SetTexture("_MainTex", m_generatedTexture);
		}
	}

	private Color _MixColor(Color color0, Color color1, float mixFactor) {
		Color mixColor = Color.white;
		mixColor.r = Mathf.Lerp(color0.r, color1.r, mixFactor);
		mixColor.g = Mathf.Lerp(color0.g, color1.g, mixFactor);
		mixColor.b = Mathf.Lerp(color0.b, color1.b, mixFactor);
		mixColor.a = Mathf.Lerp(color0.a, color1.a, mixFactor);
		return mixColor;
	}

	private Texture2D _GenerateProceduralTexture() {
		Texture2D proceduralTexture = new Texture2D(textureWidth, textureWidth);

		// The interval between circles
		float circleInterval = textureWidth / 4.0f;
		// The radius of circles
		float radius = textureWidth / 10.0f;
		// The blur factor 模糊边界所使用的参数
		float edgeBlur = 1.0f / blurFactor;

		for (int w = 0; w < textureWidth; w++) {
			for (int h = 0; h < textureWidth; h++) {
				// Initalize the pixel with background color
				Color pixel = backgroundColor;

				// Draw nine circles one by one
				for (int i = 0; i < 3; i++) {
					for (int j = 0; j < 3; j++) {
						// Compute the center of current circle
						Vector2 circleCenter = new Vector2(circleInterval * (i + 1), circleInterval * (j + 1));

						// Compute the distance between the pixel and the center
						float dist = Vector2.Distance(new Vector2(w, h), circleCenter) - radius;

						// Blur the edge of the circle 
                        // 模糊圆的边界 包括判断距离是否在半径外，半径内则返回平滑插值的第一项0f
						Color color = _MixColor(circleColor, new Color(pixel.r, pixel.g, pixel.b, 0.0f), Mathf.SmoothStep(0f, 1.0f, dist * edgeBlur));

						// Mix the current color with the previous color
						pixel = _MixColor(pixel, color, color.a);
					}
				}

				proceduralTexture.SetPixel(w, h, pixel);
			}
		}

		proceduralTexture.Apply();

		return proceduralTexture;
	}
}
```

###### Unity的程序材质

程序材质和它使用的程序纹理并不是在 Unity 中创建的，而是使用 Substance Designer 软件在 Unity 外部生成

我们可以从 Unity 的资源商店或网络中获取到很多免费或付费的 Substance 材质。这些材 质都是以 .sbsar 后缀的，我们可以直接把这些材质像其他资源一样拖入 Unity 项目中。

当把这些文件导入 Unity 后， Unity 就会生成 程序纹理资源 (Procedural Material Asset) 程序纹理资源可以包含 一个或多个程序材质。通过单击程序材质，我们可以在程序纹理的面板上看到该材质使用的 Unity Shader 及其属性、 生成程序纹理使用的纹理属性、材质预览等信息

### 动态效果

##### 内置变量（时间）

| name            | type   | description                                                  |
| --------------- | ------ | ------------------------------------------------------------ |
| _Time           | float4 | t是自场景加载开始所经过的时间，4个分量的值分别是 `(t/20,t,2t,3t)` |
| _SinTime        | float4 | t是时间的正弦值，四个分量的值分别是 `(t/8,t/4,t/2,t)`        |
| _CosTime        | float4 | t是时间的余弦值，四个分量的值分别是 `(t/8,t/4,t/2,t)`        |
| unity_DeltaTime | float4 | dt是时间增量，四个分量的值分别是 `(dt, 1/dt, smoothDt, 1/smoothDt)` |

- `dt`：这是当前帧与上一帧之间的时间差，也就是**帧间隔时间**。这个值在游戏运行过程中可能会有所变化，因为帧率可能会波动。
- `smoothDt`：这是一个经过平滑处理的时间增量，通常用于减少因帧率波动导致的游戏运行不稳定的情况。这个值是通过对过去几帧的`dt`值进行平均得到的。

##### 纹理动画

###### 序列帧动画

`_MainTex` 就是包含了所有关键帧图像的纹理。`_HorizontalAmount` 和`_VerticalAmount` 分别代表了该图像在水平方向和竖直方向包含的关键帧图像的个数。而 Speed 属性用于控制序列帧动画 的播放速度。

对 竖直 方向的坐标偏移需要使用减法， 这是因为在Unity中纹理坐标竖直方向的顺序（从下到上逐渐增 大）和序列帧纹理中的顺序（播放顺序是从上到下）是相反的 。 这对应了上面代码中注释掉的代 码部分。 我们可以把上述过程中的除法整合到一起，就得到了注释下方的代码

```
Shader "Unity Shaders Book/Chapter 11/Image Sequence Animation" {
	Properties {
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_MainTex ("Image Sequence", 2D) = "white" {}
    	_HorizontalAmount ("Horizontal Amount", Float) = 4
    	_VerticalAmount ("Vertical Amount", Float) = 4
    	_Speed ("Speed", Range(1, 100)) = 30
	}
	SubShader {
		// 序列帧图像通常是透明纹理，需要设置Pass相关状态来渲染透明效果
		Tags {"Queue"="Transparent" "IgnoreProjector"="True" "RenderType"="Transparent"}
		
		Pass {
			Tags { "LightMode"="ForwardBase" }
			
			ZWrite Off
			Blend SrcAlpha OneMinusSrcAlpha
			
			CGPROGRAM
			
			#pragma vertex vert  
			#pragma fragment frag
			
			#include "UnityCG.cginc"
			
			fixed4 _Color;
			sampler2D _MainTex;
			float4 _MainTex_ST;
			float _HorizontalAmount;
			float _VerticalAmount;
			float _Speed;
			  
			struct a2v {  
			    float4 vertex : POSITION; 
			    float2 texcoord : TEXCOORD0;
			};  
			
			struct v2f {  
			    float4 pos : SV_POSITION;
			    float2 uv : TEXCOORD0;
			};  
			
			v2f vert (a2v v) {  
				v2f o;  
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex);  
				o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);  
				return o;
			}  
			
			fixed4 frag (v2f i) : SV_Target {
				// 根据速度计算总时间，根据时间定位到哪个图像（在哪行哪列）
				float time = floor(_Time.y * _Speed);  
				float row = floor(time / _HorizontalAmount);
				float column = time - row * _HorizontalAmount;
				
//				half2 uv = float2(i.uv.x /_HorizontalAmount, i.uv.y / _VerticalAmount);
//				uv.x += column / _HorizontalAmount;
//				uv.y -= row / _VerticalAmount;
				half2 uv = i.uv + half2(column, -row);
				uv.x /=  _HorizontalAmount;
				uv.y /= _VerticalAmount;
				
				fixed4 c = tex2D(_MainTex, uv);
				c.rgb *= _Color;
				
				return c;
			}
			
			ENDCG
		}  
	}
	FallBack "Transparent/VertexLit"
}
```

###### 滚动背景

```
Shader "Unity Shaders Book/Chapter 11/Scrolling Background" {
	Properties {
		_MainTex ("Base Layer (RGB)", 2D) = "white" {}
		_DetailTex ("2nd Layer (RGB)", 2D) = "white" {}
		_ScrollX ("Base layer Scroll Speed", Float) = 1.0
		// scroll速度可以设置不同显示视差
		_Scroll2X ("2nd layer Scroll Speed", Float) = 1.0
		_Multiplier ("Layer Multiplier", Float) = 1
	}
	SubShader {
		Tags { "RenderType"="Opaque" "Queue"="Geometry"}
		
		Pass { 
			Tags { "LightMode"="ForwardBase" }
			
			CGPROGRAM
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "UnityCG.cginc"
			
			sampler2D _MainTex;
			sampler2D _DetailTex;
			float4 _MainTex_ST;
			float4 _DetailTex_ST;
			float _ScrollX;
			float _Scroll2X;
			float _Multiplier;
			
			struct a2v {
				float4 vertex : POSITION;
				float4 texcoord : TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float4 uv : TEXCOORD0;
			};
			
			v2f vert (a2v v) {
				v2f o;
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
				// frac是一个内置函数，用于计算一个浮点数的小数部分
				o.uv.xy = TRANSFORM_TEX(v.texcoord, _MainTex) + frac(float2(_ScrollX, 0.0) * _Time.y);
				o.uv.zw = TRANSFORM_TEX(v.texcoord, _DetailTex) + frac(float2(_Scroll2X, 0.0) * _Time.y);
				
				return o;
			}
			
			fixed4 frag (v2f i) : SV_Target {
				fixed4 firstLayer = tex2D(_MainTex, i.uv.xy);
				fixed4 secondLayer = tex2D(_DetailTex, i.uv.zw);
				// 用第二层的透明通道混合两个纹理
				fixed4 c = lerp(firstLayer, secondLayer, secondLayer.a);
				c.rgb *= _Multiplier;
				
				return c;
			}
			
			ENDCG
		}
	}
	FallBack "VertexLit"
}
```

##### 顶点动画

###### 流动

`_MainTex` 是河流纹理， `_Color` 用于控制整体颜色， `_Magnitude` 用于控制水流波动的幅 度， `_Frequency` 用于控制波动频率，`_InvWaveLength` 是波浪的长度的倒数， _Speed 用于控制河流纹理的移动速度。

```
Shader "Unity Shaders Book/Chapter 11/Water" {
	Properties {
		_MainTex ("Main Tex", 2D) = "white" {}
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_Magnitude ("Distortion Magnitude", Float) = 1
 		_Frequency ("Distortion Frequency", Float) = 1
 		_InvWaveLength ("Distortion Inverse Wave Length", Float) = 10
 		_Speed ("Speed", Float) = 0.5
	}
	SubShader {
		// Need to disable batching because of the vertex animation
		Tags {"Queue"="Transparent" "IgnoreProjector"="True" "RenderType"="Transparent" "DisableBatching"="True"}
		// DisableBatching：批处理会合并模型，而本例需要对模型顶点偏移 所以不能用批处理
		
		Pass {
			Tags { "LightMode"="ForwardBase" }
			
			ZWrite Off
			Blend SrcAlpha OneMinusSrcAlpha
			Cull Off
			
			CGPROGRAM  
			#pragma vertex vert 
			#pragma fragment frag
			
			#include "UnityCG.cginc" 
			
			sampler2D _MainTex;
			float4 _MainTex_ST;
			fixed4 _Color;
			float _Magnitude;
			float _Frequency;
			float _InvWaveLength;
			float _Speed;
			
			struct a2v {
				float4 vertex : POSITION;
				float4 texcoord : TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float2 uv : TEXCOORD0;
			};
			
			v2f vert(a2v v) {
				v2f o;
				
				float4 offset;
				offset.yzw = float3(0.0, 0.0, 0.0);
				// 模型的不同位置计算不同的位移量
				offset.x = sin(_Frequency * _Time.y + v.vertex.x * _InvWaveLength + v.vertex.y * _InvWaveLength + v.vertex.z * _InvWaveLength) * _Magnitude;
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex + offset);
				
				o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);
				o.uv +=  float2(0.0, _Time.y * _Speed);
				
				return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed4 c = tex2D(_MainTex, i.uv);
				c.rgb *= _Color.rgb;
				
				return c;
			} 
			
			ENDCG
		}
	}
	FallBack "Transparent/VertexLit"
}
```

###### 广告牌Billboard

本质是构建旋转矩阵。广告牌技术使用的基向批通常就是表面法线 (normal) 、指向上的方向 (up)、 指向右的方向 (right) 除此之外，我们还需要指定一个锚点 (anchor location), 这个锚点在旋转过程中是固定不变的， 以此来确定多边形在空间中的位置。

计算过程通常是，我们首先会通过初始计算得到目标的表面法线（例如就是视角方向）和指向上的方向 ，而两者往往是不垂直的。但是，两者其中之一是固定的，例如当模拟草丛时，我们希望广告牌的指向上的方向永远 (0, 1, 0), 而法线方向应该随视角变化；而当模拟粒子效果时，我们希望广告牌的法线方向是固定的，即总是指向视角方向，指向上的方向则可以发生变化

假设法线方向是固定的（法线是观察方向，因为需要将模型的法线和观察方向视为一致），首先根据初始的表面法线和指向上的方向来计算出目标方向的指向右的方向
$$
right=up \crossproduct normal
$$
对其归一化后，再由法线方向和指向右的方向计算出正交的指向上的方向即可： 
$$
up'=normal \crossproduct right
$$
构造以法线的方向为其中一个基向量的三个互相垂直基向量

```
Shader "Unity Shaders Book/Chapter 11/Billboard" {
	Properties {
		_MainTex ("Main Tex", 2D) = "white" {}
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_VerticalBillboarding ("Vertical Restraints", Range(0, 1)) = 1 
	}
	SubShader {
		// Need to disable batching because of the vertex animation
		Tags {"Queue"="Transparent" "IgnoreProjector"="True" "RenderType"="Transparent" "DisableBatching"="True"}
		
		Pass { 
			Tags { "LightMode"="ForwardBase" }
			
			ZWrite Off
			Blend SrcAlpha OneMinusSrcAlpha
			Cull Off
		
			CGPROGRAM
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			
			sampler2D _MainTex;
			float4 _MainTex_ST;
			fixed4 _Color;
			fixed _VerticalBillboarding;
			
			struct a2v {
				float4 vertex : POSITION;
				float4 texcoord : TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float2 uv : TEXCOORD0;
			};
			
			v2f vert (a2v v) {
				v2f o;
				
				// 当_VerticalBillboarding是1，意味着法线方向固定为视角方向；
				// 当_VerticalBillboarding为0，意味着向上方向固定为(0,1,0) 
				// Suppose the center in object space is fixed
				float3 center = float3(0, 0, 0);
				// 利用内置变量获取模型空间的视角
				float3 viewer = mul(_World2Object,float4(_WorldSpaceCameraPos, 1));
				
				float3 normalDir = viewer - center;
				// If _VerticalBillboarding equals 1, we use the desired view dir as the normal dir
				// Which means the normal dir is fixed
				// Or if _VerticalBillboarding equals 0, the y of normal is 0
				// Which means the up dir is fixed
				normalDir.y =normalDir.y * _VerticalBillboarding;
				normalDir = normalize(normalDir);
				// Get the approximate up dir
				// If normal dir is already towards up, then the up dir is towards front
				float3 upDir = abs(normalDir.y) > 0.999 ? float3(0, 0, 1) : float3(0, 1, 0);
				float3 rightDir = normalize(cross(upDir, normalDir));
				upDir = normalize(cross(normalDir, rightDir));
				
				// 得到了所需的3个正交基矢量
				// 我们根据原始的位置相对锚点的偏移量以及3个正交基矢量计算得出
				// Use the three vectors to rotate the quad
				float3 centerOffs = v.vertex.xyz - center;
				float3 localPos = center + rightDir * centerOffs.x + upDir * centerOffs.y + normalDir * centerOffs.z;
              	// 再将顶点位置转到裁剪空间
				o.pos = mul(UNITY_MATRIX_MVP, float4(localPos, 1));
				o.uv = TRANSFORM_TEX(v.texcoord,_MainTex);

				return o;
			}
			
			fixed4 frag (v2f i) : SV_Target {
				fixed4 c = tex2D (_MainTex, i.uv);
				c.rgb *= _Color.rgb;
				
				return c;
			}
			
			ENDCG
		}
	} 
	FallBack "Transparent/VertexLit"
}
```

取消批处理会带来一定的性能下降，增加了 Draw Call, 因此我 们应该尽量避免使用模型空间下的一些绝对位置和方向来进行计算。在广告牌的例子中，为了避免显式使用模型空间的中心来作为铀点，我们可以利用顶点颜色来存储每个顶点到铀点的距离值。

###### 注意事项

因为批处理会把**模型空间中的顶点优化掉**，但是因为我们使用了模型空间中的顶点进行计算，所以要**禁用批处理**。如果要恢复批处理，就不应该使用模型空间的顶点，那么就需要别的手段获取**模型空间的顶点位置**，因此可以考虑将存储顶点颜色的位置用来存储顶点在空间中的距离

取消批处理会带来一定的性能下降，增加了 Draw Call, 因此我 们应该尽量避免使用模型空间下的一些绝对位置和方向来进行计算。在广告牌的例子中，为了避免显式使用模型空间的中心来作为铀点，我们可以利用顶点颜色来存储每个顶点到锚点的距离值。

使用顶点动画因为对顶点的位置进行了更改，那么**阴影shader没法正确渲染**，要自己实现

```
Shader "Unity Shaders Book/Chapter 11/Vertex Animation With Shadow" {
	Properties {
		_MainTex ("Main Tex", 2D) = "white" {}
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_Magnitude ("Distortion Magnitude", Float) = 1
 		_Frequency ("Distortion Frequency", Float) = 1
 		_InvWaveLength ("Distortion Inverse Wave Length", Float) = 10
 		_Speed ("Speed", Float) = 0.5
	}
	SubShader {
		// Need to disable batching because of the vertex animation
		Tags {"DisableBatching"="True"}
		
		Pass {
			Tags { "LightMode"="ForwardBase" }
			
			Cull Off
			
			CGPROGRAM  
			#pragma vertex vert 
			#pragma fragment frag
			
			#include "UnityCG.cginc" 
			
			sampler2D _MainTex;
			float4 _MainTex_ST;
			fixed4 _Color;
			float _Magnitude;
			float _Frequency;
			float _InvWaveLength;
			float _Speed;
			
			struct a2v {
			    float4 vertex : POSITION;
			    float4 texcoord : TEXCOORD0;
			};
			
			struct v2f {
			    float4 pos : SV_POSITION;
			    float2 uv : TEXCOORD0;
			};
			
			v2f vert(a2v v) {
				v2f o;
				
				float4 offset;
				offset.yzw = float3(0.0, 0.0, 0.0);
				offset.x = sin(_Frequency * _Time.y + v.vertex.x * _InvWaveLength + v.vertex.y * _InvWaveLength + v.vertex.z * _InvWaveLength) * _Magnitude;
				o.pos = mul(UNITY_MATRIX_MVP, v.vertex + offset);
				
				o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);
				o.uv +=  float2(0.0, _Time.y * _Speed);
				
				return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
				fixed4 c = tex2D(_MainTex, i.uv);
				c.rgb *= _Color.rgb;
				
				return c;
			} 
			
			ENDCG
		}
		
		// Pass to render object as a shadow caster
		Pass {
			Tags { "LightMode" = "ShadowCaster" }
			
			CGPROGRAM
			
			#pragma vertex vert
			#pragma fragment frag
			
			#pragma multi_compile_shadowcaster
			
			#include "UnityCG.cginc"
			
			float _Magnitude;
			float _Frequency;
			float _InvWaveLength;
			float _Speed;
			
			struct v2f { 
			    V2F_SHADOW_CASTER;
			};
			
			v2f vert(appdata_base v) {
				v2f o;
				
				float4 offset;
				offset.yzw = float3(0.0, 0.0, 0.0);
				offset.x = sin(_Frequency * _Time.y + v.vertex.x * _InvWaveLength + v.vertex.y * _InvWaveLength + v.vertex.z * _InvWaveLength) * _Magnitude;
				v.vertex = v.vertex + offset;

				TRANSFER_SHADOW_CASTER_NORMALOFFSET(o)
				
				return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {
			    SHADOW_CASTER_FRAGMENT(i)
			}
			ENDCG
		}
	}
	FallBack "VertexLit"
}
```

